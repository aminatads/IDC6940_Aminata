---
title: "LASSO Regression - Spring 2026 "
subtitle: "Determining Predictors in Survival for Breast Cancer Patients"
author: "Stephanie Hopkins & Aminata Gado Oumarou (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

## Introduction

The LASSO (Least Absolute Shrinkage and Selection Operator) regression model has become increasingly popular over the past 30 years. It was first introduced by Robert Tibshirani as a method for variable selection and regularization to improve prediction accuracy and interpretability. Since then, LASSO has been widely applied across many fields, including biology, computational social sciences, social media, the stock market, economics, political science, robotics, climatology, and pharmacology [@emmert2019high].
Regression is a fundamental task in supervised machine learning, used to model relationships between variables and address key challenges such as parameter estimation and variable selection [@muthukrishnan2016lasso]. As machine learning methods continue to grow in popularity and show strong results, their importance in research has increased. In medicine especially, predictive models developed through machine learning can help professionals distinguish between risk groups, design personalized treatment plans, and improve patient survival outcomes [@huang2023practical].
LASSO regression works by minimizing prediction error while applying a constraint that shrinks some regression coefficients toward zero [@ranstam2018lasso]. It does this by adding an L1 penalty term to the loss function, which constrains the sum of the absolute values of the coefficients [@ranstam2018lasso]. This penalty forces weaker predictors to exactly zero, effectively performing automatic variable selection [@usman2021comparing]. In other words, LASSO minimizes the residual sum of squares subject to a constraint on the absolute values of the coefficients, producing models that are simpler and easier to interpret [@tibshirani1996regression]. By reducing overfitting and focusing on the most relevant predictors, LASSO creates more interpretable models, which is especially important in clinical survival analysis where clarity and reproducibility matter [@ranstam2018lasso]. It is also effective for handling large-scale problems and high-dimensional data [@roth2004generalized].
The goal of this analysis is to use LASSO regression to identify the factors most strongly associated with survival in breast cancer patients. Cancer continues to have a major impact worldwide. In 2025, an estimated 2,041,910 new cancer cases will be diagnosed in the United States, and approximately 618,120 people are expected to die from the disease [@nci2025statistics]. Breast cancer remains a significant public health concern. By 2019, more than 3.8 million individuals in the United States were living with breast cancer, and it is still the most commonly diagnosed cancer among women and the second most common cancer globally [@usman2021comparing]. Breast cancer begins in the breastâ€™s feeding tissues and develops in the epithelial cells of the ducts (85% of cases) and lobules (15%). Causes include hereditary factors, age, postmenopausal obesity, alcohol or smoking, and other factors [@hadba2024comparison]. Identifying the clinical and demographic factors most strongly linked to survival can help improve prognostic models and support better clinical decision-making. Previous research has identified numerous factors associated with breast cancer prognosis and survival. These factors are commonly grouped into three categories: (1) demographic and genetic characteristics, such as age at diagnosis, marital status, and reproductive history; (2) clinicopathological factors, including tumor location, size, and histologic grade; and (3) treatment-related variables, such as drug therapy, radiotherapy, and chemotherapy [@teng2022dynamic].
To accomplish this, the analysis uses the Surveillance, Epidemiology, and End Results (SEER) dataset to determine the most important variables associated with breast cancer survivability. SEER has collected and maintained high-quality, validated data on mortality among cancer survivors, allowing for analysis of overall and cause-specific death patterns [@xu2022lasso]. The dataset includes variables such as age, race, marital status, T stage, N stage, 6th stage, grade, A stage, tumor size, estrogen status, progesterone status, regional nodes examined, regional nodes positive, survival months, and status.
Although LASSO regression has been valuable across many research areas, it is particularly useful in medical studies where identifying the most influential predictors is essential for improving patient outcomes. Using the SEER data, this study applies LASSO regression for feature selection to identify key clinical variables associated with breast cancer survival while reducing overfitting and improving model stability [@lee2025machine].


## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{python}
import pandas as pd
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
